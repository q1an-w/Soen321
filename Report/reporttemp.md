Credit Card Fraud Detection Security Tests: An Analysis of Machine Learning Model Vulnerabilities

Authors:
Karina Sanchez-Duran (40189860)
Qian Yi Wang (40211303)
Paul Humennyj (40209588)
Vanessa DiPietrantonio (40189938)
Mohamad Mounir Yassin (40198854)
Yash Patel (40175454)

# Page 1: Key Findings Summary

## Major Findings

- [Key finding 1]
- [Key finding 2]
- [Key finding 3]

## Security Implications

- [Security implication 1]
- [Security implication 2]
- [Security implication 3]

## Recommendations

- [Recommendation 1]
- [Recommendation 2]
- [Recommendation 3]

# Pages 2-4: Methodologies and Tools

## 1. Base Model Implementation

### 1.1 Dataset Description

### 1.2 Model Architecture

### 1.3 Training Methodology

### 1.4 Baseline Performance Metrics

## 2. Attack Implementations

### 2.1 Adversarial Attacks

#### 2.1.1 White-box Attacks

#### 2.1.2 Black-box Attacks

### 2.2 Evasion Attacks

In order to check the robustness of the trained fraud detection model, we implemented multiple evasionattacks based on input generated by a surrogate (black-box) model. These attack make a scenario where an attacker, having no acces to the internal model, crafts inputs to evade fraud detection at test time.

Each evasion attack slightly perturbs known fraudulent inputs and tests whether the modified inputs are misclassified as non-fraud by the original decision tree classifier. The goal is to determine how easily fraud can bypass detection with minimal manipulation.

We structured our attacks using separate strategy scripts to preserve clarity and modular testing.

#### Strategy A (Decision Tree Classifier):

This strategy reduced the values of `feature5` and `feature7` by 1, assuming these features contribute significantly to fraud detection. After applying this transformation and testing against the original model, we achieved:

- **Evasion Success**: 35 out of 226 samples
- **Success Rate**: **15.49%**
  The result shows that even small input modifications to key features can lead to incorrect non-fraud classification by the model.

#### Strategy A (Random Forest Classifier)

Strategy A was applied to the Random Forest classifier by decreasing feature5 and feature7 by 1 for each known fraudulent input, in line with the decision tree test. This strategy targeted features suspected to heavily influence the fraud prediction outcome.

After transformation and scaling, predictions were evaluated against the original model. The results were as follows:

- **Evasion Success: 27 out of 149 samples**
- **Success Rate: 18.12%**
  Although the evasion success rate was still relatively low, it outperformed the decision tree’s 15.49%, suggesting that the Random Forest is slightly more vulnerable to this type of targeted feature reduction. This shows that even ensemble models can be evaded with minimal, targeted manipulation under black-box assumptions.

#### Strategy A (Gradient Boosting Classifier)

The same Strategy A—reducing feature5 and feature7 by 1—was evaluated against the Gradient Boosting Classifier to test its robustness to minimal, targeted changes.

Despite the model's more complex ensemble structure, the attack succeeded on 52 of 230 known fraudulent inputs:

- **Evasion Success: 52 out of 230**
- **Success Rate: 22.61%**
  This makes Gradient Boosting the most vulnerable among all three models tested under Strategy A. The results suggest that while GB models are typically more accurate, they may also be more sensitive to small feature changes, especially when trained with strong patterns that can be easily nudged.

#### Strategy B (Decision Tree Classifier):

This strategy incremented the values of `feature3` and `feature6` by 1 for each fraudulent input. These changes were hypothesized to make fraudulent behavior appear more benign.

- **Evasion Success**: 226 out of 226 samples
- **Success Rate**: **100.00%**

This strategy was completely successful. The model misclassified every modified fraudulent input as legitimate, highlighting a critical vulnerability. Even slight increases in these two features significantly impacted the model's decision boundary.

#### Strategy B (Random Forest Classifier)

This evasion strategy aimed to exploit weaknesses in the Random Forest fraud detection model by subtly modifying specific features of known fraudulent inputs. In particular:

- `feature3` was increased by +1
- `feature6` was increased by +1
  These changes were based on the hypothesis that boosting these two feature values would make fraudulent behavior appear more "normal" to the model.

Results:

- **Evasion Success: 149 out of 149 samples**
- **Success Rate: 100.00%**
  The Random Forest classifier failed to flag any of the modified fraudulent records, indicating a severe vulnerability to this specific perturbation. The attack was completely successful, as every altered sample evaded detection.

#### Strategy B (Gradient Boosting Classifier)

We tested Strategy B on the Gradient Boosting model to evaluate whether this more sophisticated ensemble classifier could resist subtle, targeted input manipulation. This attack increases `feature3` and `feature6` by 1 for every fraudulent input in the dataset.

The results were even more concerning than with the Random Forest. The Gradient Boosting model misclassified every single altered fraudulent input as legitimate, revealing a severe vulnerability to this type of attack.

- **Evasion Success:** 230 out of 230
- **Success Rate:** **100.00%**

These findings show that while Gradient Boosting is typically more accurate in baseline predictions, it may be more brittle under adversarial pressure. Slight increases in specific features can fully collapse its fraud detection performance, likely due to its reliance on fine-grained decision thresholds that shift easily under targeted input noise.

#### Strategy C (Decision Tree Classifier):

This strategy randomly perturbed every feature (either +1 or -1) for each fraudulent record. It simulates a real-world scenario where an attacker modifies multiple features slightly to evade detection without knowing which ones matter.

- **Evasion Success:** 169 out of 226 samples
- **Success Rate**: **74.78%**

The high success rate highlights the model’s vulnerability to widespread but subtle feature changes. Even without targeting specific features, nearly 75% of the modified fraudulent inputs were misclassified as legitimate. While not as precise as Strategy B, this approach still bypassed the model in the majority of cases. It suggests that the model's decision boundary is highly sensitive to broad feature noise, not just targeted changes.

#### Strategy C (Random Forest Classifier)

This strategy simulates a real-world black-box scenario where an attacker, unaware of specific feature importance, slightly perturbs every feature (+1 or -1) of known fraudulent inputs. This method tests how well the Random Forest model handles broad, subtle noise.

After modifying all features and scaling them using the original scaler, the transformed samples were passed into the Random Forest fraud detection model.

Results:

- **Evasion Success: 182 out of 226 samples**
- **Success Rate: 80.53%**

The significantly high evasion success rate implies that even without targeting any specific feature, the model is highly vulnerable to small, random perturbations across the feature space. Despite the ensemble nature of Random Forests, this result suggests insufficient robustness under non-targeted adversarial inputs, making this a serious concern for real-world deployment.

#### Strategy C (Gradient Boosting Classifier)

This strategy tested the resilience of the Gradient Boosting fraud detection model by applying random perturbations of ±1 across all features of known fraudulent inputs. The intent was to mimic realistic black-box attack behavior, where an attacker modifies every available feature slightly without knowing which ones are most influential.

Following the feature alterations and proper scaling, the modified fraudulent records were evaluated against the Gradient Boosting model.

Results:

- **Evasion Success: 186 out of 230 samples**
- **Success Rate: 80.87%**

The high evasion success rate suggests that the Gradient Boosting model is also highly susceptible to wide, low-magnitude feature changes. Despite being the most accurate model under normal conditions, its fine-grained thresholds make it more vulnerable to distributed input noise. This underlines the importance of adversarial training or input validation to protect such models in production systems.

### 2.3 Membership Inference Attacks

## 3. Testing Framework

### 3.1 Performance Testing Setup

### 3.2 Security Testing Methodology

### 3.3 Tools and Libraries Used

#### 3.3.1 Foolbox Implementation

#### 3.3.2 Locust Testing Setup

#### 3.3.3 PyTorch Adversarial Attack Tools

# Pages 5-7: Results

## 1. Model Performance Analysis

### 1.1 Baseline Model Performance

### 1.2 Performance Under Attack

## 2. Attack Effectiveness Analysis

### 2.1 Adversarial Attack Results

#### 2.1.1 White-box Attack Success Rates

#### 2.1.2 Black-box Attack Success Rates

### 2.2 Evasion Attack Results

### 2.3 Membership Inference Attack Results

## 3. Comparative Analysis

### 3.1 Attack Method Comparison

### 3.2 Resource Consumption Analysis

### 3.3 Detection Rate Analysis

# Pages 8-9: Discussion and Practical Implications

## 1. Security Vulnerability Analysis

### 1.1 Critical Vulnerabilities Identified

### 1.2 Risk Assessment

## 2. Defense Strategies

### 2.1 Proposed Countermeasures

### 2.2 Implementation Recommendations

### 2.3 Trade-offs and Limitations

## 3. Real-world Applications

### 3.1 Industry Impact

### 3.2 Implementation Considerations

### 3.3 Future Research Directions

# Page 10: References

## Tools and Libraries

## Academic References

## Dataset Sources

# Appendices

## Appendix A: Detailed Attack Results

### Strategy A

A selection of the modified fraudulent inputs and their outcomes:

| Sample | Original Feature5 | Modified Feature5 | Original Feature7 | Modified Feature7 | Prediction | Evasion Success |
| ------ | ----------------- | ----------------- | ----------------- | ----------------- | ---------- | --------------- |
| 1      | 5                 | 4                 | 5                 | 4                 | 1          | NO              |
| 4      | 4                 | 3                 | 1                 | 0                 | 0          | YES             |
| 20     | 1                 | 0                 | 1                 | 0                 | 0          | YES             |
| 47     | 3                 | 2                 | 1                 | 0                 | 0          | YES             |
| 99     | 0                 | 0                 | 2                 | 1                 | 0          | YES             |

_Full result CSV available as `results_strategy_a.csv` in the `Evasion_Strategies` folder._

### Strategy A – Random Forest

A selection of the modified fraudulent inputs and their outcomes:

| Sample | Original Feature5 | Modified Feature5 | Original Feature7 | Modified Feature7 | Prediction | Evasion Success |
| ------ | ----------------- | ----------------- | ----------------- | ----------------- | ---------- | --------------- |
| 3      | 5                 | 4                 | 1                 | 0                 | 0          | YES             |
| 10     | 3                 | 2                 | 1                 | 0                 | 0          | YES             |
| 17     | 5                 | 4                 | 0                 | 0                 | 0          | YES             |
| 26     | 2                 | 1                 | 0                 | 0                 | 0          | YES             |
| 40     | 0                 | 0                 | 2                 | 1                 | 0          | YES             |

The full result list is available in `results_strategy_a_rf.csv`in the `Evasion_Strategies` folder.

### Strategy A – Gradient Boosting

A selection of the modified fraudulent inputs and their outcomes:

| Sample | Original Feature5 | Modified Feature5 | Original Feature7 | Modified Feature7 | Prediction | Evasion Success |
| ------ | ----------------- | ----------------- | ----------------- | ----------------- | ---------- | --------------- |
| 1      | 3                 | 2                 | 1                 | 0                 | 0          | YES             |
| 4      | 4                 | 3                 | 2                 | 1                 | 0          | YES             |
| 17     | 5                 | 4                 | 2                 | 1                 | 0          | YES             |
| 36     | 4                 | 3                 | 0                 | 0                 | 0          | YES             |
| 68     | 2                 | 1                 | 4                 | 3                 | 0          | YES             |

The full result list is available in `results_strategy_a_gb.csv`in the `Evasion_Strategies` folder.

### Strategy B

A selection of modified fraudulent inputs and their outcomes:

| Sample | Original Feature3 | Modified Feature3 | Original Feature6 | Modified Feature6 | Prediction | Evasion Success |
| ------ | ----------------- | ----------------- | ----------------- | ----------------- | ---------- | --------------- |
| 1      | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 5      | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 17     | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 32     | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 100    | 5                 | 6                 | 0                 | 1                 | 0          | YES             |

_Full CSV output saved as `results_strategy_b.csv` inside the `Evasion_Strategies` folder._

### Strategy B – Random Forest

A selection of the modified fraudulent inputs and their outcomes:

| Sample | Original Feature3 | Modified Feature3 | Original Feature6 | Modified Feature6 | Prediction | Evasion Success |
| ------ | ----------------- | ----------------- | ----------------- | ----------------- | ---------- | --------------- |
| 1      | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 7      | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 22     | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 43     | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 90     | 5                 | 6                 | 0                 | 1                 | 0          | YES             |

_Full CSV output saved as `results_strategy_b_rf.csv` inside the `Evasion_Strategies` folder._

### Strategy B – Gradient Boosting

A selection of the modified fraudulent inputs and their outcomes:

| Sample | Original Feature3 | Modified Feature3 | Original Feature6 | Modified Feature6 | Prediction | Evasion Success |
| ------ | ----------------- | ----------------- | ----------------- | ----------------- | ---------- | --------------- |
| 1      | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 6      | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 17     | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 42     | 5                 | 6                 | 0                 | 1                 | 0          | YES             |
| 107    | 5                 | 6                 | 0                 | 1                 | 0          | YES             |

_The full result list is available in `results_strategy_b_gb.csv` inside the `Evasion_Strategies` folder._

### Strategy C

A selection of randomly modified fraudulent inputs and their outcomes:

| Sample | Feature Changed | Original Value | Modified Value | Prediction | Evasion Success |
| ------ | --------------- | -------------- | -------------- | ---------- | --------------- |
| 1      | feature2        | 0              | 1              | 1          | NO              |
| 2      | feature6        | 0              | 1              | 0          | YES             |
| 9      | feature7        | 3              | 4              | 0          | YES             |
| 21     | feature5        | 1              | 0              | 0          | YES             |
| 46     | feature6        | 0              | 1              | 0          | YES             |

_Full result CSV available as `results_strategy_c.csv` in the `Evasion_Strategies` folder._

### Strategy C – Random Forest

A selection of randomly modified fraudulent inputs and their outcomes:

| Sample | Feature Changed | Original Value | Modified Value | Prediction | Evasion Success |
| ------ | --------------- | -------------- | -------------- | ---------- | --------------- |
| 1      | feature1        | 2              | 3              | 0          | YES             |
| 3      | feature5        | 0              | 1              | 0          | YES             |
| 7      | feature2        | 5              | 4              | 0          | YES             |
| 15     | feature4        | 5              | 4              | 1          | NO              |
| 42     | feature6        | 0              | 1              | 0          | YES             |

_Full result CSV available as `results_strategy_c_rf.csv` in the `Evasion_Strategies` folder._

### Strategy C - Gradient Boosting

| Feature1 | Feature2 | Feature3 | Feature4 | Feature5 | Feature6 | Feature7 | Target | Prediction | Evasion_Success |
| -------- | -------- | -------- | -------- | -------- | -------- | -------- | ------ | ---------- | --------------- |
| 4        | 5        | 5        | 5        | 3        | 0        | 1        | 1      | 0.0        | YES             |
| 5        | 4        | 5        | 0        | 0        | 0        | 5        | 1      | 0.0        | YES             |
| 2        | 5        | 5        | 2        | 4        | 0        | 1        | 1      | 1.0        | NO              |
| 0        | 0        | 5        | 0        | 4        | 0        | 3        | 1      | 1.0        | NO              |
| 0        | 5        | 5        | 4        | 1        | 0        | 4        | 1      | 0.0        | YES             |
| ...      | ...      | ...      | ...      | ...      | ...      | ...      | ...    | ...        | ...             |
| 5        | 5        | 5        | 4        | 4        | 0        | 4        | 1      | 0.0        | YES             |
| 0        | 5        | 5        | 0        | 2        | 0        | 5        | 1      | 0.0        | YES             |

_Full result CSV available as `results_strategy_c_gb.csv` in the `Evasion_Strategies` folder._

## Appendix B: Code Snippets

## Appendix C: Additional Performance Metrics

## Appendix D: Test Cases

## Appendix E: Implementation Details
